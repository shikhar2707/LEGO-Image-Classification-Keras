# -*- coding: utf-8 -*-
"""Q1_Training_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h7k6bRYP27CprjGwfuDs1wY1qew1DUtt
"""

import numpy as np
import pandas as pd
import math
import tensorflow as tf

!pip install tensorflow

!pip install keras

!pip install Keras-Applications

!pip install keras-resnet

image.shape, image

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
from skimage.io import imread, imshow

image = imread('D:/Q1/question_1_dataset/train/train/2000.png', as_gray=True)
imshow(image)

image.resize(28,28,refcheck = False)

image.shape, image

from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D

num_classes = 16

my_new_model = Sequential()
my_new_model.add(ResNet50(include_top=False, pooling='avg'))
my_new_model.add(Dense(num_classes, activation='softmax'))

my_new_model.layers[0].trainable = False

my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])

from google.colab import files
uploaded = files.upload()

get_ipython().system_raw("unrar x train")

train_path= 'train'
validation_path = 'train'
#test_path='D:/Q1/question_1_dataset/test/'

from tensorflow.python.keras.preprocessing.image import ImageDataGenerator

from tensorflow.python.keras.applications.resnet50 import ResNet50

model = ResNet50(include_top = True,weights = "imagenet",input_tensor = None,input_shape = None,pooling = None,classes = 1000)

image_size = 200

data_generator_with_aug = ImageDataGenerator(
                                   horizontal_flip=True,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2)

train_generator = data_generator_with_aug.flow_from_directory(
        train_path,
        target_size=(image_size, image_size),
        batch_size=24,
        class_mode='categorical')

validation_generator = data_generator_with_aug.flow_from_directory(train_path,
        target_size=(image_size, image_size),
        class_mode='categorical')

compute_steps_per_epoch = lambda x: int(math.ceil(1. * x / 24))
 
steps_per_epoch = compute_steps_per_epoch(4465)
val_steps = compute_steps_per_epoch(4465)
steps_per_epoch

my_new_model.fit_generator(
        train_generator,
        steps_per_epoch=187,
        epochs = 35,
        validation_data=validation_generator,
        validation_steps=187)

my_new_model.save("model.h5")

from google.colab import files
uploaded = files.upload()

!unzip test.zip

import cv2
import numpy as np

final_predictions = []
for i in range(4466,6380):
  img = cv2.imread("test" + "/" + str(i) + ".png")
  img = cv2.resize(img,(200,200))
  img = np.reshape(img,[1,200,200,3])
  final_predictions.append(my_new_model.predict_classes(img , batch_size = 24))
final_predictions

(final_predictions[0][0])

fp = []
for k in range(1914):
  fp.append(final_predictions[k][0] + 1)
fp

Index = []
for j in range(4466,6380):
  Index.append(str(j))
Index

Predictions_Dataframe = pd.DataFrame()

Predictions_Dataframe["Index"] = Index

Predictions_Dataframe["Categories"] = fp

Predictions_Dataframe

from google.colab import drive
drive.mount('drive')

Predictions_Dataframe.to_csv("Submission.csv")
!cp Submission.csv "drive/My Drive/"

